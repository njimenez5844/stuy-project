{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9444bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "# Neural networks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Add, Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Embedding\n",
    "from tensorflow.keras.layers import Flatten, Concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import regularizers\n",
    "# Wrapper to make neural network compitable with StackingRegressor\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# Linear model as meta-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Create generic dataset for regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d501b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression dataset\n",
    "data = pd.read_csv('train2.csv')\n",
    "data.drop('Id',axis=1 , inplace=True)\n",
    "tfidf = TfidfVectorizer()\n",
    "#intializing the TfidVectorizer object... helps vectorize and normalize the data using a logarithmic function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54aa483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CommentsToBeTokenized = data['Comment'] \n",
    "tfidf_result=tfidf.fit_transform(CommentsToBeTokenized).toarray()\n",
    "vectorizer = TfidfVectorizer(max_features= 6000)\n",
    "tfidf_result = vectorizer.fit_transform(CommentsToBeTokenized).toarray()\n",
    "tfidf_result = vectorizer.fit_transform(CommentsToBeTokenized).toarray()\n",
    "features = vectorizer.get_feature_names_out()\n",
    "tfidf_result = pd.DataFrame(tfidf_result, columns=features)\n",
    "X_train, X_val, y_train, y_val = train_test_split(tfidf_result, data['Topic'], test_size= 0.2, random_state = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fd66ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>019</th>\n",
       "      <th>02</th>\n",
       "      <th>020</th>\n",
       "      <th>021</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>07</th>\n",
       "      <th>...</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtu</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yt</th>\n",
       "      <th>yup</th>\n",
       "      <th>zeolites</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zone</th>\n",
       "      <th>zp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7383</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7324 rows Ã— 6000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000   01  019   02  020  021   03   04   07  ...  yourself  youtu  \\\n",
       "8504  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "3434  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "2841  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "3679  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "7383  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...    ...   \n",
       "2944  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "4527  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "6525  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "2109  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "2176  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0    0.0   \n",
       "\n",
       "      youtube   yt  yup  zeolites  zero      zinc  zone   zp  \n",
       "8504      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "3434      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "2841      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "3679      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "7383      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "...       ...  ...  ...       ...   ...       ...   ...  ...  \n",
       "2944      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "4527      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "6525      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "2109      0.0  0.0  0.0       0.0   0.0  0.000000   0.0  0.0  \n",
       "2176      0.0  0.0  0.0       0.0   0.0  0.065594   0.0  0.0  \n",
       "\n",
       "[7324 rows x 6000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e2a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network(input_shape, depth=4, batch_mod=2, num_neurons=20, drop_rate=0.1, learn_rate=.01,\n",
    "                      r1_weight=0.02,\n",
    "                      r2_weight=0.02):\n",
    "    '''A neural network architecture built using keras functional API'''\n",
    "    act_reg = l1(r2_weight)\n",
    "    kern_reg = l1(r1_weight)\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    batch1 = BatchNormalization()(inputs)\n",
    "    hidden1 = Dense(num_neurons, activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(batch1)\n",
    "    dropout1 = Dropout(drop_rate)(hidden1)\n",
    "    hidden2 = Dense(int(num_neurons/2), activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(dropout1)\n",
    "    \n",
    "    skip_list = [batch1]\n",
    "    last_layer_in_loop = hidden2\n",
    "    \n",
    "    for i in range(depth):\n",
    "        added_layer = concatenate(skip_list + [last_layer_in_loop])\n",
    "        skip_list.append(added_layer)\n",
    "        b1 = None\n",
    "        #Apply batch only on every i % N layers\n",
    "        if i % batch_mod == 2:\n",
    "            b1 = BatchNormalization()(added_layer)\n",
    "        else:\n",
    "            b1 = added_layer\n",
    "        \n",
    "        h1 = Dense(num_neurons, activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(b1)\n",
    "        d1 = Dropout(drop_rate)(h1)\n",
    "        h2 = Dense(int(num_neurons/2), activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(d1)\n",
    "        d2 = Dropout(drop_rate)(h2)\n",
    "        h3 =  Dense(int(num_neurons/2), activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(d2)\n",
    "        d3 = Dropout(drop_rate)(h3)\n",
    "        h4 =  Dense(int(num_neurons/2), activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(d3)\n",
    "        last_layer_in_loop = h4\n",
    "        c1 = concatenate(skip_list + [last_layer_in_loop])\n",
    "        output = Dense(1, activation='sigmoid')(c1)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    optimizer = Adam()\n",
    "    optimizer.learning_rate = learn_rate\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6d6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is for regression... have to figure out how to mold this into a classifier thing \n",
    "\n",
    "def get_stacking(input_shape=None):\n",
    "    '''A stacking model that consists of CatBoostRegressor,\n",
    "    XGBRegressor, a linear model, and some neural networks'''\n",
    "    # First we create a list called \"level0\", which consists of our base models\"\n",
    "    # These models will get passed down to the meta-learner later\n",
    "    level0 = list()\n",
    "    level0.append(('KNeighborsClassifier',  KNeighborsClassifier(n_neighbors= 4)))\n",
    "    level0.append(('MultinomialNB', MultinomialNB(alpha = 0.1)))\n",
    "    level0.append(('RandomForest', RandomForestClassifier(max_depth = 9)))\n",
    "#Create 5 neural networks using our function above\n",
    "    for i in range(5):\n",
    "        # Wrap our neural network in a Keras Regressor to make it\n",
    "        #compatible with StackingRegressor\n",
    "        keras_class = KerasClassifier(\n",
    "                create_neural_network, # Pass in function\n",
    "                input_shape=input_shape, # Pass in the dimensions to above function\n",
    "                epochs=6,\n",
    "                batch_size=32,\n",
    "                verbose=0)\n",
    "        keras_class._estimator_type = \"classifier\"\n",
    "        # Append to our list\n",
    "        level0.append(('nn_{num}'.format(num=i), keras_class))\n",
    "# The \"meta-learner\" designated as the level1 model\n",
    "    # In my experience Linear Regression performs best\n",
    "    # but feel free to experiment with other models\n",
    "    level1 = MultinomialNB() \n",
    "# Create the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=2, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00435573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serap\\AppData\\Local\\Temp\\ipykernel_4708\\4277335599.py:16: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_class = KerasClassifier(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator KNeighborsClassifier should be a regressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\94855511.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create stacking model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stacking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# Creating a temporary dataframe so we can see how each of our models performed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    757\u001b[0m         \"\"\"\n\u001b[0;32m    758\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# all_estimators contains all estimators, the one to be fitted and the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# 'drop' string.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_final_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"drop\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    263\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[0;32m    264\u001b[0m                         \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The estimator KNeighborsClassifier should be a regressor."
     ]
    }
   ],
   "source": [
    "#Get our input dimensions for neural network\n",
    "input_dimensions = len(X_train.columns)\n",
    "# Create stacking model\n",
    "model = get_stacking(input_dimensions)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "# Creating a temporary dataframe so we can see how each of our models performed\n",
    "temp = pd.DataFrame(y_val)\n",
    "# The stacked models predictions, which should perform the best\n",
    "temp['stacking_prediction'] = model.predict(X_val)\n",
    "# Get each model in the stacked model to see how they individually perform\n",
    "for m in model.named_estimators_:\n",
    "        temp[m] = model.named_estimators_[m].predict(X_val)\n",
    "# See how each of our models correlate with our target\n",
    "print(temp.corr()['target'])\n",
    "# See what our meta-learner is thinking (the linear regression)\n",
    "for coef in zip(model.named_estimators_, model.final_estimator_.coef_):\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "891cd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c0810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n",
      "Accuracy: 0.42 (+/- 0.01) [KNN]\n",
      "Accuracy: 0.48 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.71 (+/- 0.00) [Multinomial Naive Bayes]\n",
      "Accuracy: 0.50 (+/- 0.01) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors= 4, weights = 'distance', leaf_size = 20 )\n",
    "clf2 = RandomForestClassifier(max_depth = 9)\n",
    "clf3 = MultinomialNB(alpha = 0.1)\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=lr)\n",
    "\n",
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, sclf], \n",
    "                      ['KNN', \n",
    "                       'Random Forest', \n",
    "                       'Multinomial Naive Bayes',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X_train, y_train, \n",
    "                                              cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))\n",
    "#Other cross validation methods had a run time error... time to try Keras! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6afc945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier as newSC \n",
    "base_learners = [\n",
    "                 ('rf_1', RandomForestClassifier(n_estimators=10, random_state=42, max_depth = 9)),\n",
    "                 ('rf_2', KNeighborsClassifier(n_neighbors=5)),\n",
    "                 ('rf_3', MultinomialNB(alpha = 0.1))\n",
    "                ]\n",
    "\n",
    "# Initialize Stacking Classifier with the Meta Learner\n",
    "clf = newSC(estimators=base_learners, final_estimator=LogisticRegression())\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18f0447c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf_1',\n",
       "                                RandomForestClassifier(max_depth=9,\n",
       "                                                       n_estimators=10,\n",
       "                                                       random_state=42)),\n",
       "                               ('rf_2', KNeighborsClassifier()),\n",
       "                               ('rf_3', MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "#Taking way longer than expected.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f1fb7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.82      0.92      0.87       745\n",
      "   Chemistry       0.86      0.82      0.84       568\n",
      "     Physics       0.90      0.79      0.84       426\n",
      "\n",
      "    accuracy                           0.85      1739\n",
      "   macro avg       0.86      0.84      0.85      1739\n",
      "weighted avg       0.85      0.85      0.85      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.74      0.82      0.78       791\n",
      "   Chemistry       0.67      0.63      0.65       550\n",
      "     Physics       0.76      0.64      0.70       398\n",
      "\n",
      "    accuracy                           0.72      1739\n",
      "   macro avg       0.72      0.70      0.71      1739\n",
      "weighted avg       0.72      0.72      0.72      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred1 = clf.predict(X_train)\n",
    "ypred = clf.predict(X_val)\n",
    "ytrain = y_train[0:1739]\n",
    "ytest = y_val[0:1739]\n",
    "ypred1 = ypred1[0:1739]\n",
    "ypred = ypred[0:1739]\n",
    "print(\"Training Results:\\n\")\n",
    "print(classification_report(ytrain, ypred1))\n",
    "print(\"\\nTesting Results:\\n\")\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2f9c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4d40360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model.sav']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(clf, filename)\n",
    "#300 Megabytes... cannot use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ff5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "CommentsToBeTokenized = data['Comment'] \n",
    "tfidf_result=tfidf.fit_transform(CommentsToBeTokenized).toarray()\n",
    "vectorizer = TfidfVectorizer(max_features= 6000)\n",
    "tfidf_result = vectorizer.fit_transform(CommentsToBeTokenized).toarray()\n",
    "features = vectorizer.get_feature_names_out()\n",
    "tfidf_result = pd.DataFrame(tfidf_result, columns=features)\n",
    "X_train, X_val, y_train, y_val = train_test_split(tfidf_result, data['Topic'], test_size= 0.2, random_state = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "978c371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = MultinomialNB(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1af4958a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60487ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model.sav']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(clf3, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59752204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
