{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import genesis\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler as MMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A few things. You might have negative- frequen...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it so hard to believe that there exist part...</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are bees</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm a medication technician. And that's alot o...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cesium is such a pretty metal.</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment      Topic\n",
       "0  A few things. You might have negative- frequen...    Biology\n",
       "1  Is it so hard to believe that there exist part...    Physics\n",
       "2                                     There are bees    Biology\n",
       "3  I'm a medication technician. And that's alot o...    Biology\n",
       "4                     Cesium is such a pretty metal.  Chemistry"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train2.csv')\n",
    "data.drop('Id', axis=1 , inplace=True)\n",
    "data.head()\n",
    "#This data isn't extremely good — it's just reddit comments that were labeled with a specific topic\n",
    "#There might be some noise to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8695, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "#intializing the TfidVectorizer object... helps vectorize and normalize the data using a logarithmic function \n",
    "CommentsToBeTokenized = data['Comment'] \n",
    "tfidf_result=tfidf.fit_transform(CommentsToBeTokenized).toarray()\n",
    "#transforming each comment into an n-dimensional vector, making a matrix out of all of the comments  \n",
    "tfidf_result #most of these are 0 because the word doesn't appear in the sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8695, 18177)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_result.shape #18177 unique strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 6000)\n",
    "#changing the TfidVectorizer object... this is because I did some hyperparameter testing with max features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_result = vectorizer.fit_transform(CommentsToBeTokenized).toarray()\n",
    "tfidf_result #sparse matrix of size (8695, 6000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>019</th>\n",
       "      <th>02</th>\n",
       "      <th>020</th>\n",
       "      <th>021</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>07</th>\n",
       "      <th>09</th>\n",
       "      <th>...</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtu</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yt</th>\n",
       "      <th>yup</th>\n",
       "      <th>zeolites</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   01  019   02  020  021   03   04   07   09  ...  yours  yourself  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0       0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0       0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0       0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0       0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0       0.0   \n",
       "\n",
       "   youtu  youtube   yt  yup  zeolites  zero  zinc   zp  \n",
       "0    0.0      0.0  0.0  0.0       0.0   0.0   0.0  0.0  \n",
       "1    0.0      0.0  0.0  0.0       0.0   0.0   0.0  0.0  \n",
       "2    0.0      0.0  0.0  0.0       0.0   0.0   0.0  0.0  \n",
       "3    0.0      0.0  0.0  0.0       0.0   0.0   0.0  0.0  \n",
       "4    0.0      0.0  0.0  0.0       0.0   0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 6000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_result = vectorizer.fit_transform(CommentsToBeTokenized).toarray()\n",
    "features = vectorizer.get_feature_names_out()\n",
    "tfidf_result = pd.DataFrame(tfidf_result, columns=features)\n",
    "tfidf_result.head()\n",
    "#There are some random collections of characters, but that's expected given our quality of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_result, data['Topic'], test_size= 0.2, random_state = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.85      0.35      0.50       730\n",
      "   Chemistry       0.64      0.16      0.25       571\n",
      "     Physics       0.31      0.91      0.46       438\n",
      "\n",
      "    accuracy                           0.43      1739\n",
      "   macro avg       0.60      0.47      0.40      1739\n",
      "weighted avg       0.64      0.43      0.41      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.45      0.93      0.61       730\n",
      "   Chemistry       0.60      0.15      0.23       571\n",
      "     Physics       0.60      0.12      0.20       438\n",
      "\n",
      "    accuracy                           0.47      1739\n",
      "   macro avg       0.55      0.40      0.35      1739\n",
      "weighted avg       0.54      0.47      0.38      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.70      0.36      0.48       730\n",
      "   Chemistry       0.53      0.06      0.11       571\n",
      "     Physics       0.31      0.91      0.46       438\n",
      "\n",
      "    accuracy                           0.40      1739\n",
      "   macro avg       0.51      0.44      0.35      1739\n",
      "weighted avg       0.55      0.40      0.35      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.54      0.27      0.36       730\n",
      "   Chemistry       0.36      0.68      0.47       571\n",
      "     Physics       0.27      0.18      0.21       438\n",
      "\n",
      "    accuracy                           0.38      1739\n",
      "   macro avg       0.39      0.38      0.35      1739\n",
      "weighted avg       0.41      0.38      0.36      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.54      0.26      0.35       730\n",
      "   Chemistry       0.35      0.68      0.46       571\n",
      "     Physics       0.34      0.19      0.25       438\n",
      "\n",
      "    accuracy                           0.38      1739\n",
      "   macro avg       0.41      0.38      0.35      1739\n",
      "weighted avg       0.43      0.38      0.36      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.59      0.24      0.34       730\n",
      "   Chemistry       0.36      0.71      0.47       571\n",
      "     Physics       0.33      0.23      0.27       438\n",
      "\n",
      "    accuracy                           0.39      1739\n",
      "   macro avg       0.43      0.39      0.36      1739\n",
      "weighted avg       0.45      0.39      0.37      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.58      0.16      0.26       730\n",
      "   Chemistry       0.34      0.74      0.47       571\n",
      "     Physics       0.33      0.22      0.26       438\n",
      "\n",
      "    accuracy                           0.37      1739\n",
      "   macro avg       0.42      0.37      0.33      1739\n",
      "weighted avg       0.44      0.37      0.33      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.58      0.16      0.25       730\n",
      "   Chemistry       0.35      0.78      0.48       571\n",
      "     Physics       0.31      0.18      0.23       438\n",
      "\n",
      "    accuracy                           0.37      1739\n",
      "   macro avg       0.41      0.37      0.32      1739\n",
      "weighted avg       0.44      0.37      0.32      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.57      0.14      0.23       730\n",
      "   Chemistry       0.34      0.77      0.47       571\n",
      "     Physics       0.28      0.18      0.22       438\n",
      "\n",
      "    accuracy                           0.36      1739\n",
      "   macro avg       0.40      0.36      0.31      1739\n",
      "weighted avg       0.42      0.36      0.31      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,10):\n",
    "    model = KNC(n_neighbors= k )\n",
    "    model.fit(x_train, y_train)\n",
    "    y_predicted = model.predict(x_test)\n",
    "    print(\"\\nTesting Results:\\n\")\n",
    "    print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = MultinomialNB(alpha = 1) \n",
    "#again, this is from hyperparameter testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = NB.predict(x_train)\n",
    "ypred = NB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1739,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = y_train[0:1739]\n",
    "ytest = y_test[0:1739]\n",
    "ypred1 = ypred1[0:1739]\n",
    "ypred = ypred[0:1739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.73      0.93      0.82       723\n",
      "   Chemistry       0.82      0.76      0.79       580\n",
      "     Physics       0.95      0.60      0.74       436\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.83      0.77      0.78      1739\n",
      "weighted avg       0.81      0.79      0.79      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.64      0.89      0.75       730\n",
      "   Chemistry       0.71      0.62      0.66       571\n",
      "     Physics       0.89      0.46      0.61       438\n",
      "\n",
      "    accuracy                           0.70      1739\n",
      "   macro avg       0.75      0.66      0.67      1739\n",
      "weighted avg       0.73      0.70      0.69      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Results:\\n\")\n",
    "print(classification_report(ytrain, ypred1))\n",
    "print(\"\\nTesting Results:\\n\")\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = clf.predict(x_train)\n",
    "ypred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = y_train[0:1739]\n",
    "ytest = y_test[0:1739]\n",
    "ypred1 = ypred1[0:1739]\n",
    "ypred = ypred[0:1739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.47      1.00      0.64       723\n",
      "   Chemistry       0.98      0.22      0.36       580\n",
      "     Physics       1.00      0.14      0.25       436\n",
      "\n",
      "    accuracy                           0.52      1739\n",
      "   macro avg       0.81      0.45      0.41      1739\n",
      "weighted avg       0.77      0.52      0.45      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.45      0.99      0.62       730\n",
      "   Chemistry       0.85      0.13      0.23       571\n",
      "     Physics       0.96      0.11      0.20       438\n",
      "\n",
      "    accuracy                           0.49      1739\n",
      "   macro avg       0.76      0.41      0.35      1739\n",
      "weighted avg       0.71      0.49      0.39      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Results:\\n\")\n",
    "print(classification_report(ytrain, ypred1))\n",
    "print(\"\\nTesting Results:\\n\")\n",
    "print(classification_report(ytest, ypred))\n",
    "#overfitting on the chemistry and physics dataset... might not be good for predicting biology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We probably want to use multinomialNB to perform predictions \n",
    "def online_test(question, right_label):\n",
    "    # convert the question to a vector, using an already existing vector.\n",
    "    # There is a subtle issue here - if question includes a word that\n",
    "    # isn't already in the dataset, the transformer/vectorizor won't handle\n",
    "    # this.\n",
    "    #\n",
    "    # This can be solved, but with careful consideration. Read about online \n",
    "    # feature extraction for text for some solutions. \n",
    "    #\n",
    "    # Online tf-idf example https://github.com/idoshlomo/online_vectorizers\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_result=tfidf.fit_transform(CommentsToBeTokenized).toarray()\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=6000)\n",
    "    tfidf_result = vectorizer.fit_transform(CommentsToBeTokenized).toarray()\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "    tfidf_result = pd.DataFrame(tfidf_result, columns=features)\n",
    "    \n",
    "    question_as_sparse_matrix = vectorizer.transform([question])\n",
    "    question_as_vector = np.array(question_as_sparse_matrix.todense())\n",
    "\n",
    "    # creates a new model \n",
    "    NB= MultinomialNB()\n",
    "\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(tfidf_result, data['Topic'], test_size= 0.2)\n",
    "    NB.fit(xtrain, ytrain)\n",
    "\n",
    "    ypred1 = NB.predict(xtrain)\n",
    "    ypred = NB.predict(xtest)\n",
    "\n",
    "    ytrain=ytrain[0:1739]\n",
    "    ytest=ytest[0:1739]\n",
    "    ypred1 = ypred1[0:1739]\n",
    "    ypred = ypred[0:1739]\n",
    "\n",
    "    # predict the label\n",
    "    prediction = NB.predict(question_as_vector)\n",
    "    results = {'Comment': question, 'Topic': right_label, 'Guess' : prediction[0]}\n",
    "    print(results) \n",
    "    # check if the prediction is correct\n",
    "    if prediction[0] == right_label:\n",
    "        return \"Correct\"\n",
    "    else:\n",
    "        return \"Incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Comment': 'What is molecular orbital theory?', 'Topic': 'Chemistry', 'Guess': 'Chemistry'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Correct'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_test(\"What is molecular orbital theory?\", \"Chemistry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Comment': 'What types of molecules are aromatic? What about non-aromatic?', 'Topic': 'Chemistry', 'Guess': 'Chemistry'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Correct'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_test(\"What types of molecules are aromatic? What about non-aromatic?\", \"Chemistry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_vectorizers import OnlineTfidfVectorizer\n",
    "online_tfidf = OnlineTfidfVectorizer()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNC().get_params().keys()\n",
    "a = [3, 4, 5, 6, 7]  \n",
    "    \n",
    "KNC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 20}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= ['uniform', 'distance']\n",
    "a = []  \n",
    "for i in range (4, 8): \n",
    "    a.append(i * 5)\n",
    "gs_knn = GridSearchCV (KNC(), param_grid = {'leaf_size': a}, scoring = 'accuracy', cv = 5)\n",
    "gs_knn.fit(x_train, y_train)\n",
    "gs_knn.best_params_\n",
    "\n",
    "# gs_knn.best_params_  n_neighbors = 4 \n",
    "# weights = distance \n",
    "#leaf_size = 20 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for i in range (1, 20): \n",
    "    a.append(i * 0.01)\n",
    "gs_nb = GridSearchCV (MultinomialNB(), param_grid = {'alpha': a}, scoring = 'accuracy', cv = 5)\n",
    "gs_nb.fit(x_train, y_train)\n",
    "gs_nb.best_params_\n",
    "#best parameter is alpha = 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.73      0.93      0.82       723\n",
      "   Chemistry       0.82      0.76      0.79       580\n",
      "     Physics       0.95      0.60      0.74       436\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.83      0.77      0.78      1739\n",
      "weighted avg       0.81      0.79      0.79      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.64      0.89      0.75       730\n",
      "   Chemistry       0.71      0.62      0.66       571\n",
      "     Physics       0.89      0.46      0.61       438\n",
      "\n",
      "    accuracy                           0.70      1739\n",
      "   macro avg       0.75      0.66      0.67      1739\n",
      "weighted avg       0.73      0.70      0.69      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MultinomialNB(alpha = 0.1)\n",
    "NB.fit(x_train, y_train)\n",
    "ypred1 = NB.predict(x_train)\n",
    "ypred = NB.predict(x_test)\n",
    "ytrain = y_train[0:1739]\n",
    "ytest = y_test[0:1739]\n",
    "ypred1 = ypred1[0:1739]\n",
    "ypred = ypred[0:1739]\n",
    "print(\"Training Results:\\n\")\n",
    "print(classification_report(ytrain, ypred1))\n",
    "print(\"\\nTesting Results:\\n\")\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.65      0.39      0.49       730\n",
      "   Chemistry       0.39      0.69      0.49       571\n",
      "     Physics       0.31      0.20      0.25       438\n",
      "\n",
      "    accuracy                           0.44      1739\n",
      "   macro avg       0.45      0.43      0.41      1739\n",
      "weighted avg       0.48      0.44      0.43      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNC(n_neighbors= 4, weights = 'distance', leaf_size = 20 )\n",
    "model.fit(x_train, y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "print(\"\\nTesting Results:\\n\")\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_knn = GridSearchCV (RandomForestClassifier(), param_grid = {'leaf_size': a}, scoring = 'accuracy', cv = 5)\n",
    "gs_knn.fit(x_train, y_train)\n",
    "gs_knn.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
